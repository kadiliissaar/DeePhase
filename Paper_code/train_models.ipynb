{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, roc_auc_score\n",
    "\n",
    "RandomSeed = 42\n",
    "np.random.seed(RandomSeed)\n",
    "\n",
    "sns.set(font_scale = 1.4)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 6, \"ytick.major.size\": 0})\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", False)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "sns.set(font_scale = 1.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df_training, training_categories, num_trials, model_name, clf):\n",
    "    df_training = df_training[df_training['Category'].isin(training_categories)]\n",
    "    df_training['Category'] = df_training['Category'].map({str(training_categories[0]): 1, training_categories[1]: 0})\n",
    "    df_training = df_training.reset_index(drop=True)\n",
    "    df_training = df_training.reindex(sorted(df_training.columns), axis=1)\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits = num_trials, test_size = 0.1, random_state=42)\n",
    "    \n",
    "    y = df_training['Category']\n",
    "    groups = df_training['Uniprot_ID']\n",
    "    X = df_training.drop(columns={'Category', 'Uniprot_ID', 'Sequence'})\n",
    "    \n",
    "    accuracy = []; precision = []\n",
    "    recall = []; roc_auc = []\n",
    "    for train_index, test_index in gss.split(X, y, groups=groups):\n",
    "        clf.fit(X.loc[train_index], y.loc[train_index])\n",
    "        score = clf.score(X.loc[test_index], y.loc[test_index])\n",
    "        accuracy.append(accuracy_score(clf.predict(X.loc[test_index]), y.loc[test_index]))\n",
    "        precision.append(precision_score(clf.predict(X.loc[test_index]), y.loc[test_index]))\n",
    "        recall.append(recall_score(clf.predict(X.loc[test_index]), y.loc[test_index]))\n",
    "        roc_auc.append(roc_auc_score(y.loc[test_index], clf.predict_proba(X.loc[test_index])[:,1]))\n",
    "    print('Random forest model: accuracy =' + str(sum(accuracy)/num_trials) + '+/-' + str(np.std(accuracy)/np.sqrt(num_trials)))\n",
    "    print('Random forest model: precision =' + str(sum(precision)/num_trials) + '+/-' + str(np.std(precision)/np.sqrt(num_trials)))\n",
    "    print('Random forest model: recall =' + str(sum(recall)/num_trials) + '+/-' + str(np.std(recall)/np.sqrt(num_trials)))\n",
    "    print('Random forest model: ROC-AUC =' + str(sum(roc_auc)/num_trials) + '+/-' + str(np.std(roc_auc)/np.sqrt(num_trials)))\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    pickle.dump(clf, open('Models/' + str(model_name) + '.sav', 'wb'))\n",
    "    \n",
    "\n",
    "    \n",
    "def predict(model_name, df_predictions, data_set_name):\n",
    "    model = pickle.load(open('Models/' + str(model_name) + '.sav', 'rb'))\n",
    "    df_predictions = df_predictions.reset_index(drop=True)\n",
    "    df_predictions = df_predictions.reindex(sorted(df_predictions.columns), axis=1)\n",
    "    \n",
    "    trial = df_predictions.drop(['Uniprot_ID', 'Category', 'Sequence'], axis=1).to_numpy()\n",
    "    df_predictions['prediction'] = model.predict_proba(trial)[:,1]\n",
    "    df_predictions = df_predictions.rename(columns={\"prediction\": \"prediction_\" + str(model_name)})\n",
    "    df_predictions.to_csv('Predictions/' + str(data_set_name) + '/predictions_' + str(model_name) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multicat_model(df_training, num_trials, model_name, clf):\n",
    "    df_training['Category'] = df_training['Category'].map({'LLPS+': 0, 'LLPS-': 1, 'PDB*': 2})\n",
    "    df_training = df_training.reset_index(drop = True)\n",
    "    df_training = df_training.reindex(sorted(df_training.columns), axis=1)\n",
    "\n",
    "    y = df_training['Category']\n",
    "    groups = df_training['Uniprot_ID']\n",
    "    X = df_training.drop(columns={'Category', 'Uniprot_ID', 'Sequence'})\n",
    "    clf.fit(X, y)\n",
    "    pickle.dump(clf, open('Models/' + str(model_name) + '.sav', 'wb'))\n",
    "\n",
    "def predict_multiclass(model_name, df_predictions, data_set_name):\n",
    "    model = pickle.load(open('Models/' + str(model_name) + '.sav', 'rb'))\n",
    "    df_predictions = df_predictions.reset_index(drop=True)\n",
    "    df_predictions = df_predictions.reindex(sorted(df_predictions.columns), axis=1)\n",
    "\n",
    "    trial = df_predictions.drop(['Uniprot_ID', 'Category', 'Sequence'], axis=1).to_numpy()\n",
    "    df_predictions['prediction'] = model.predict_proba(trial)[:,0] + 0.5* model.predict_proba(trial)[:,1]\n",
    "    df_predictions = df_predictions.rename(columns={\"prediction\": \"prediction_\" + str(model_name)})\n",
    "    df_predictions.to_csv('Predictions/' + str(data_set_name) + '/predictions_' + str(model_name) +  '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_csv('Features/training_data_features.csv')\n",
    "swissprot_all = pd.read_csv('Features/swissprot_features.csv')\n",
    "overlapping = swissprot_all[swissprot_all['Uniprot_ID'].isin(combined['Uniprot_ID'])]\n",
    "swissprot_train_removed = swissprot_all[swissprot_all['Uniprot_ID'].isin(overlapping['Uniprot_ID']) == False]\n",
    "\n",
    "ext_pos = pd.read_csv('Features/external_data_pos_features.csv')\n",
    "ext_neg = pd.read_csv('Features/external_data_neg_features.csv')\n",
    "ext_pos['Category'] = 'ext_pos'\n",
    "ext_neg['Category'] = 'ext_neg'\n",
    "\n",
    "\n",
    "data_all = pd.concat([swissprot_train_removed, combined, ext_pos, ext_neg], axis = 0)\n",
    "data_all = data_all[data_all['Sequence_length'] > 6]\n",
    "data_all = data_all[data_all['Sequence_length'] < 6000]\n",
    "data_all = data_all.drop(columns = ['LCR_sequence', 'reshuffled_sequence', 'delta_5_HB_RS'])\n",
    "\n",
    "w2v_cols = data_all.columns[[col.isdigit() for col in data_all.columns]]\n",
    "data_w2v = data_all[w2v_cols]\n",
    "info_cols = ['Uniprot_ID', 'Sequence', 'Category']\n",
    "data_w2v = pd.concat([data_w2v, data_all[info_cols]], axis = 1)\n",
    "\n",
    "phys_feature_cols_temp = list(np.setdiff1d(list(data_all.columns), info_cols))\n",
    "phys_feature_cols = list(np.setdiff1d(phys_feature_cols_temp, w2v_cols))\n",
    "data_phys = data_all[phys_feature_cols]\n",
    "data_info = data_all[info_cols]\n",
    "data_phys = pd.concat([data_phys, data_all[info_cols]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & predictions on Swiss-Prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-642d93db321c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training['Category'] = df_training['Category'].map({str(training_categories[0]): 1, training_categories[1]: 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model: accuracy =0.9381384102975026+/-0.007935073272259969\n",
      "Random forest model: precision =0.9221392374395471+/-0.014262076975556648\n",
      "Random forest model: recall =0.9453181587400655+/-0.013138980734518826\n",
      "Random forest model: ROC-AUC =0.9678019999092754+/-0.007451111892813176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-642d93db321c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training['Category'] = df_training['Category'].map({str(training_categories[0]): 1, training_categories[1]: 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model: accuracy =0.6433872055064213+/-0.01618602072047163\n",
      "Random forest model: precision =0.7368189592594743+/-0.025700170764370554\n",
      "Random forest model: recall =0.6857878891740486+/-0.024105425103566315\n",
      "Random forest model: ROC-AUC =0.6939131172672168+/-0.018119491139988834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-642d93db321c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training['Category'] = df_training['Category'].map({str(training_categories[0]): 1, training_categories[1]: 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model: accuracy =0.8906718087603118+/-0.014146195346163229\n",
      "Random forest model: precision =0.9534256919551037+/-0.011889409669450656\n",
      "Random forest model: recall =0.8788694606047548+/-0.017412622168814878\n",
      "Random forest model: ROC-AUC =0.9039794486436459+/-0.02233283555040995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-438d43cfe171>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training['Category'] = df_training['Category'].map({'LLPS+': 0, 'LLPS-': 1, 'PDB*': 2})\n"
     ]
    }
   ],
   "source": [
    "#1. Physical features\n",
    "data_phys_sel = data_phys[{'Category', 'Uniprot_ID',\n",
    "         'Hydrophobicity', 'Shannon_entropy', 'LCR_frac', 'IDR_frac',\n",
    "         'Arom_frac', 'Cation_frac', 'Sequence',\n",
    "         }]\n",
    "\n",
    "clf_phys = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "\n",
    "\n",
    "#Binary models\n",
    "n = 25\n",
    "training_categories = ['LLPS+', 'PDB*']\n",
    "training_data = data_phys_sel[data_phys_sel['Category'].isin(['LLPS+', 'LLPS-', 'PDB*'])]\n",
    "phys_features_pred_1 = train_model(training_data, training_categories, num_trials = n, model_name = 'phys_1', clf = clf_phys)\n",
    "\n",
    "predict_on_SP = data_phys_sel[data_phys_sel['Category'] == 'Swiss-Prot']\n",
    "predict_on_ext_pos = data_phys_sel[data_phys_sel['Category'] == 'ext_pos']\n",
    "predict_on_ext_neg = data_phys_sel[data_phys_sel['Category'] == 'ext_neg']\n",
    "predict('phys_1', predict_on_SP, 'Swissprot')\n",
    "predict('phys_1', predict_on_ext_neg, 'ext_neg')\n",
    "predict('phys_1', predict_on_ext_pos, 'ext_pos')\n",
    "\n",
    "training_categories = ['LLPS+', 'LLPS-']\n",
    "training_data = data_phys_sel[data_phys_sel['Category'].isin(['LLPS+', 'LLPS-', 'PDB*'])]\n",
    "phys_features_pred_2 = train_model(training_data, training_categories, num_trials = n, model_name = 'phys_2', clf = clf_phys)\n",
    "\n",
    "predict_on_SP = data_phys_sel[data_phys_sel['Category'] == 'Swiss-Prot']\n",
    "predict_on_ext_pos = data_phys_sel[data_phys_sel['Category'] == 'ext_pos']\n",
    "predict_on_ext_neg = data_phys_sel[data_phys_sel['Category'] == 'ext_neg']\n",
    "predict('phys_2', predict_on_SP, 'Swissprot')\n",
    "predict('phys_2', predict_on_ext_neg, 'ext_neg')\n",
    "predict('phys_2', predict_on_ext_pos, 'ext_pos')\n",
    "\n",
    "training_categories = ['PDB*', 'LLPS-']\n",
    "training_data = data_phys_sel[data_phys_sel['Category'].isin(['LLPS+', 'LLPS-', 'PDB*'])]\n",
    "phys_features_pred_3 = train_model(training_data, training_categories, num_trials = n, model_name = 'phys_3', clf = clf_phys)\n",
    "\n",
    "predict_on_SP = data_phys_sel[data_phys_sel['Category'] == 'Swiss-Prot']\n",
    "predict_on_ext_pos = data_phys_sel[data_phys_sel['Category'] == 'ext_pos']\n",
    "predict_on_ext_neg = data_phys_sel[data_phys_sel['Category'] == 'ext_neg']\n",
    "predict('phys_3', predict_on_SP, 'Swissprot')\n",
    "predict('phys_3', predict_on_ext_neg, 'ext_neg')\n",
    "predict('phys_3', predict_on_ext_pos, 'ext_pos')\n",
    "\n",
    "\n",
    "#Multiclass model\n",
    "clf_phys = RandomForestClassifier(n_estimators = 50, max_depth = 5, random_state = 42)\n",
    "training_data = data_phys_sel[data_phys_sel['Category'].isin(['LLPS+', 'LLPS-', 'PDB*'])]\n",
    "phys_features_pred_multi = train_multicat_model(training_data, num_trials = 25, model_name = 'phys_multi', clf = clf_phys)\n",
    "\n",
    "predict_on_SP = data_phys_sel[data_phys_sel['Category'] == 'Swiss-Prot']\n",
    "predict_on_ext_pos = data_phys_sel[data_phys_sel['Category'] == 'ext_pos']\n",
    "predict_on_ext_neg = data_phys_sel[data_phys_sel['Category'] == 'ext_neg']\n",
    "predict_multiclass('phys_multi', predict_on_SP, 'Swissprot')\n",
    "predict_multiclass('phys_multi', predict_on_ext_neg, 'ext_neg')\n",
    "predict_multiclass('phys_multi', predict_on_ext_pos, 'ext_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-642d93db321c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training['Category'] = df_training['Category'].map({str(training_categories[0]): 1, training_categories[1]: 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model: accuracy =0.912546500501352+/-0.011239810713163993\n",
      "Random forest model: precision =0.842050184650804+/-0.027644120510572513\n",
      "Random forest model: recall =0.9705757575757576+/-0.009619519706620932\n",
      "Random forest model: ROC-AUC =0.9825583676958289+/-0.004332965944618376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-642d93db321c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training['Category'] = df_training['Category'].map({str(training_categories[0]): 1, training_categories[1]: 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model: accuracy =0.6609274491914741+/-0.02024918277490066\n",
      "Random forest model: precision =0.749958105108383+/-0.03153301855452162\n",
      "Random forest model: recall =0.7035283409401057+/-0.024532376212781547\n",
      "Random forest model: ROC-AUC =0.7164512290336532+/-0.01928082232416829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-642d93db321c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training['Category'] = df_training['Category'].map({str(training_categories[0]): 1, training_categories[1]: 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model: accuracy =0.876543442701069+/-0.016080770136648152\n",
      "Random forest model: precision =0.9819694031458739+/-0.006469361176672539\n",
      "Random forest model: recall =0.8448485674971744+/-0.02323571406787151\n",
      "Random forest model: ROC-AUC =0.9161270437017894+/-0.01545078132500868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-438d43cfe171>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_training['Category'] = df_training['Category'].map({'LLPS+': 0, 'LLPS-': 1, 'PDB*': 2})\n"
     ]
    }
   ],
   "source": [
    "#2. Models with w2v embeddings:\n",
    "clf_w2v = RandomForestClassifier(n_estimators = 100, max_depth = 5, random_state = 42)\n",
    "\n",
    "#Binary models\n",
    "n = 25\n",
    "training_categories = ['LLPS+', 'PDB*']\n",
    "training_data = data_w2v[data_w2v['Category'].isin(['LLPS+', 'LLPS-', 'PDB*'])]\n",
    "w2v_pred_1 = train_model(training_data, training_categories, num_trials = n, model_name = 'w2v_1', clf = clf_w2v)\n",
    "\n",
    "predict_on_SP = data_w2v[data_w2v['Category'] == 'Swiss-Prot']\n",
    "predict_on_ext_pos = data_w2v[data_w2v['Category'] == 'ext_pos']\n",
    "predict_on_ext_neg = data_w2v[data_w2v['Category'] == 'ext_neg']\n",
    "predict('w2v_1', predict_on_SP, 'Swissprot')\n",
    "predict('w2v_1', predict_on_ext_neg, 'ext_neg')\n",
    "predict('w2v_1', predict_on_ext_pos, 'ext_pos')\n",
    "\n",
    "training_categories = ['LLPS+', 'LLPS-']\n",
    "training_data = data_w2v[data_w2v['Category'].isin(['LLPS+', 'LLPS-', 'PDB*'])]\n",
    "w2v_pred_2 = train_model(training_data, training_categories, num_trials = n, model_name = 'w2v_2', clf = clf_w2v)\n",
    "predict_on_SP = data_w2v[data_w2v['Category'] == 'Swiss-Prot']\n",
    "predict_on_ext_pos = data_w2v[data_w2v['Category'] == 'ext_pos']\n",
    "predict_on_ext_neg = data_w2v[data_w2v['Category'] == 'ext_neg']\n",
    "predict('w2v_2', predict_on_SP, 'Swissprot')\n",
    "predict('w2v_2', predict_on_ext_neg, 'ext_neg')\n",
    "predict('w2v_2', predict_on_ext_pos, 'ext_pos')\n",
    "\n",
    "training_categories = ['PDB*', 'LLPS-']\n",
    "training_data = data_w2v[data_w2v['Category'].isin(['LLPS+', 'LLPS-', 'PDB*'])]\n",
    "w2v_pred_3 = train_model(training_data, training_categories, num_trials = n, model_name = 'w2v_3', clf = clf_w2v)\n",
    "predict_on_SP = data_w2v[data_w2v['Category'] == 'Swiss-Prot']\n",
    "predict_on_ext_pos = data_w2v[data_w2v['Category'] == 'ext_pos']\n",
    "predict_on_ext_neg = data_w2v[data_w2v['Category'] == 'ext_neg']\n",
    "predict('w2v_3', predict_on_SP, 'Swissprot')\n",
    "predict('w2v_3', predict_on_ext_neg, 'ext_neg')\n",
    "predict('w2v_3', predict_on_ext_pos, 'ext_pos')\n",
    "\n",
    "#Multiclass model\n",
    "training_data = data_w2v[data_w2v['Category'].isin(['LLPS+', 'LLPS-', 'PDB*'])]\n",
    "w2v_pred_multi = train_multicat_model(training_data, num_trials = 25, model_name = 'w2v_multi', clf = clf_w2v)\n",
    "predict_on_SP = data_w2v[data_w2v['Category'] == 'Swiss-Prot']\n",
    "predict_on_ext_pos = data_w2v[data_w2v['Category'] == 'ext_pos']\n",
    "predict_on_ext_neg = data_w2v[data_w2v['Category'] == 'ext_neg']\n",
    "predict_multiclass('w2v_multi', predict_on_SP, 'Swissprot')\n",
    "predict_multiclass('w2v_multi', predict_on_ext_neg, 'ext_neg')\n",
    "predict_multiclass('w2v_multi', predict_on_ext_pos, 'ext_pos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Swissprot'\n",
    "phys_pred_1 = pd.read_csv('Predictions/' + str(category) + '/predictions_phys_1.csv')\n",
    "phys_pred_2 = pd.read_csv('Predictions/' + str(category) +'/predictions_phys_2.csv')\n",
    "phys_pred_multi = pd.read_csv('Predictions/' + str(category) + '/predictions_phys_multi.csv')\n",
    "\n",
    "w2v_pred_1 = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_1.csv')\n",
    "w2v_pred_2 = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_2.csv')\n",
    "w2v_pred_multi = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_multi.csv')\n",
    "\n",
    "\n",
    "predictions = pd.concat([phys_pred_1[{'Category', 'Uniprot_ID', 'Sequence', 'prediction_phys_1'}],\n",
    "                phys_pred_2[{'prediction_phys_2'}],\n",
    "                phys_pred_multi[{'prediction_phys_multi'}],\n",
    "                w2v_pred_1[{'prediction_w2v_1'}],\n",
    "                w2v_pred_2[{'prediction_w2v_2'}],\n",
    "                w2v_pred_multi[{'prediction_w2v_multi'}]], axis = 1)\n",
    "\n",
    "predictions.to_csv('Predictions/' + str(category) + '/all_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'ext_pos'\n",
    "phys_pred_1 = pd.read_csv('Predictions/' + str(category) + '/predictions_phys_1.csv')\n",
    "phys_pred_2 = pd.read_csv('Predictions/' + str(category) +'/predictions_phys_2.csv')\n",
    "phys_pred_multi = pd.read_csv('Predictions/' + str(category) + '/predictions_phys_multi.csv')\n",
    "\n",
    "w2v_pred_1 = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_1.csv')\n",
    "w2v_pred_2 = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_2.csv')\n",
    "w2v_pred_multi = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_multi.csv')\n",
    "\n",
    "\n",
    "predictions = pd.concat([phys_pred_1[{'Category', 'Uniprot_ID', 'Sequence', 'prediction_phys_1'}],\n",
    "                phys_pred_2[{'prediction_phys_2'}],\n",
    "                phys_pred_multi[{'prediction_phys_multi'}],\n",
    "                w2v_pred_1[{'prediction_w2v_1'}],\n",
    "                w2v_pred_2[{'prediction_w2v_2'}],\n",
    "                w2v_pred_multi[{'prediction_w2v_multi'}]], axis = 1)\n",
    "\n",
    "predictions.to_csv('Predictions/' + str(category) + '/all_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'ext_neg'\n",
    "phys_pred_1 = pd.read_csv('Predictions/' + str(category) + '/predictions_phys_1.csv')\n",
    "phys_pred_2 = pd.read_csv('Predictions/' + str(category) +'/predictions_phys_2.csv')\n",
    "phys_pred_multi = pd.read_csv('Predictions/' + str(category) + '/predictions_phys_multi.csv')\n",
    "\n",
    "w2v_pred_1 = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_1.csv')\n",
    "w2v_pred_2 = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_2.csv')\n",
    "w2v_pred_multi = pd.read_csv('Predictions/' + str(category) + '/predictions_w2v_multi.csv')\n",
    "\n",
    "predictions = pd.concat([phys_pred_1[{'Category', 'Uniprot_ID', 'Sequence', 'prediction_phys_1'}],\n",
    "                phys_pred_2[{'prediction_phys_2'}],\n",
    "                phys_pred_multi[{'prediction_phys_multi'}],\n",
    "                w2v_pred_1[{'prediction_w2v_1'}],\n",
    "                w2v_pred_2[{'prediction_w2v_2'}],\n",
    "                w2v_pred_multi[{'prediction_w2v_multi'}]], axis = 1)\n",
    "\n",
    "predictions.to_csv('Predictions/' + str(category) + '/all_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
